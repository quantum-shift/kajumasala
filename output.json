[
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/blog",
    "text": "Blog\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nOn track to help 1 million people regain their voice\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nWe’re partnering with Star Sports to localize cricket content across languages\nHow text to speech enhances virtual tours and immersive experiences\nAnnouncing the ElevenLabs Award Winners in the Project Odyssey AI Film Competition\nRian scales global storytelling with ElevenLabs’ AI Voice technology\nThe state of AI Audio in publishing and news\nAiMation Studios uses ElevenLabs to bring characters to life\nAI Dubbing for Polish Presidency of the Council of the EU\nElevenLabs joins the EU AI Champions Initiative\nWe cut our pricing for Conversational AI\nSolda.AI launches AI voice agents that can close deals\nGemini 2.0 Flash now available\nConvin adds AI voice calling to its contact center platform\nStudio is now available to everyone\nProduction-Ready Conversational AI at Enterprise Scale: With Scale AI’s Felix Su\nArianna Huffington uses ElevenLabs to refresh Thrive for its 10th anniversary\nHow Conversational AI will change entertainment and media\nTalk to DeepSeek R1 with ElevenLabs Conversational AI\nElevenLabs raises $180M Series C to be the voice of the digital world\nFooter\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nExpanding beyond ALS to support MSA and mouth cancer patients with free AI voice technology\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nGiving cricket fans across India access to their favorite player's insights in English, Hindi, Tamil and other Indian languages.\nBring virtual experiences to life with compelling text to speech narration.\nAfter reviewing 4500 submissions (190 hours of film!) to the world's largest AI Film Festival – Project Odyssey - we can now finally reveal the grand prize winners of the ElevenLabs award.\nRian accelerates global storytelling with ElevenLabs’ AI dubbing — boosting efficiency, authenticity, and audience reach.\nAI audio is transforming the news industry, boosting engagement and accessibility through narrated articles and podcasts.\nAiMation Studios uses ElevenLabs Voice AI and sound effects models to bring characters to life and speed up its pipeline.\nPress conferences will be available in Polish, English, and French using AI-generated voices\nOver 60 companies are working to strengthen Europe’s role in global AI\nCalls now start at 10 cents per minute — an ~50% discount across Starter, Creator and Pro plans\nGemini 2.0 Flash is now available to all developers building with ElevenLabs Conversational AI\nUsing our speech technology for AI voice agents\nStudio, our longform text-to-audio editor for creators and storytellers, is now available to everyone.\nBuilding controlled AI experiences through smart architecture and guardrails\nArianna Huffington turns to ElevenLabs Voice AI technology to refresh the preface of her book Thrive for its 10th anniversary. \nConversational AI is reshaping entertainment and media, enabling more interactive and personalized experiences\nWe gave DeepSeek R1 a voice with ElevenLabs Conversational AI platform\nAnd make speech the new standard for digital interaction\nCreate with the highest quality AI Audio\nResearch\nProducts\nSolutions\nEarn As\nResources\nCompany\nReach everyone with AI audio\n© 2025 ElevenLabs"
},
{
    "url": "https://elevenlabs.io/app/sign-up",
    "text": ""
},
{
    "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
    "text": "Create speech\nPath parameters\nQuery parameters\nRequest\nResponse\nErrors\nConvert text to speech using our library of over 3,000 voices across 32 languages.\nID of the voice to be used. Use the \n endpoint list all the available voices.\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n0 - default mode (no latency optimizations)\n1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n3 - max latency optimizations\n4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\nThe output format of the generated audio.\nThe text that will get converted into speech.\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nLanguage code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.\nVoice settings overriding stored setttings for the given voice. They are applied only on the given request.\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nThe text that came before the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nThe text that comes after the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\nIf true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.\nSuccessful Response"
},
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
}
][
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/blog",
    "text": "Blog\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nOn track to help 1 million people regain their voice\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nWe’re partnering with Star Sports to localize cricket content across languages\nHow text to speech enhances virtual tours and immersive experiences\nAnnouncing the ElevenLabs Award Winners in the Project Odyssey AI Film Competition\nRian scales global storytelling with ElevenLabs’ AI Voice technology\nThe state of AI Audio in publishing and news\nAiMation Studios uses ElevenLabs to bring characters to life\nAI Dubbing for Polish Presidency of the Council of the EU\nElevenLabs joins the EU AI Champions Initiative\nWe cut our pricing for Conversational AI\nSolda.AI launches AI voice agents that can close deals\nGemini 2.0 Flash now available\nConvin adds AI voice calling to its contact center platform\nStudio is now available to everyone\nProduction-Ready Conversational AI at Enterprise Scale: With Scale AI’s Felix Su\nArianna Huffington uses ElevenLabs to refresh Thrive for its 10th anniversary\nHow Conversational AI will change entertainment and media\nTalk to DeepSeek R1 with ElevenLabs Conversational AI\nElevenLabs raises $180M Series C to be the voice of the digital world\nFooter\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nExpanding beyond ALS to support MSA and mouth cancer patients with free AI voice technology\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nGiving cricket fans across India access to their favorite player's insights in English, Hindi, Tamil and other Indian languages.\nBring virtual experiences to life with compelling text to speech narration.\nAfter reviewing 4500 submissions (190 hours of film!) to the world's largest AI Film Festival – Project Odyssey - we can now finally reveal the grand prize winners of the ElevenLabs award.\nRian accelerates global storytelling with ElevenLabs’ AI dubbing — boosting efficiency, authenticity, and audience reach.\nAI audio is transforming the news industry, boosting engagement and accessibility through narrated articles and podcasts.\nAiMation Studios uses ElevenLabs Voice AI and sound effects models to bring characters to life and speed up its pipeline.\nPress conferences will be available in Polish, English, and French using AI-generated voices\nOver 60 companies are working to strengthen Europe’s role in global AI\nCalls now start at 10 cents per minute — an ~50% discount across Starter, Creator and Pro plans\nGemini 2.0 Flash is now available to all developers building with ElevenLabs Conversational AI\nUsing our speech technology for AI voice agents\nStudio, our longform text-to-audio editor for creators and storytellers, is now available to everyone.\nBuilding controlled AI experiences through smart architecture and guardrails\nArianna Huffington turns to ElevenLabs Voice AI technology to refresh the preface of her book Thrive for its 10th anniversary. \nConversational AI is reshaping entertainment and media, enabling more interactive and personalized experiences\nWe gave DeepSeek R1 a voice with ElevenLabs Conversational AI platform\nAnd make speech the new standard for digital interaction\nCreate with the highest quality AI Audio\nResearch\nProducts\nSolutions\nEarn As\nResources\nCompany\nReach everyone with AI audio\n© 2025 ElevenLabs"
},
{
    "url": "https://elevenlabs.io/app/sign-up",
    "text": ""
},
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
    "text": "Create speech\nPath parameters\nQuery parameters\nRequest\nResponse\nErrors\nConvert text to speech using our library of over 3,000 voices across 32 languages.\nID of the voice to be used. Use the \n endpoint list all the available voices.\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n0 - default mode (no latency optimizations)\n1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n3 - max latency optimizations\n4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\nThe output format of the generated audio.\nThe text that will get converted into speech.\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nLanguage code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.\nVoice settings overriding stored setttings for the given voice. They are applied only on the given request.\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nThe text that came before the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nThe text that comes after the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\nIf true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.\nSuccessful Response"
}
][
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/blog",
    "text": "Blog\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nOn track to help 1 million people regain their voice\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nWe’re partnering with Star Sports to localize cricket content across languages\nHow text to speech enhances virtual tours and immersive experiences\nAnnouncing the ElevenLabs Award Winners in the Project Odyssey AI Film Competition\nRian scales global storytelling with ElevenLabs’ AI Voice technology\nThe state of AI Audio in publishing and news\nAiMation Studios uses ElevenLabs to bring characters to life\nAI Dubbing for Polish Presidency of the Council of the EU\nElevenLabs joins the EU AI Champions Initiative\nWe cut our pricing for Conversational AI\nSolda.AI launches AI voice agents that can close deals\nGemini 2.0 Flash now available\nConvin adds AI voice calling to its contact center platform\nStudio is now available to everyone\nProduction-Ready Conversational AI at Enterprise Scale: With Scale AI’s Felix Su\nArianna Huffington uses ElevenLabs to refresh Thrive for its 10th anniversary\nHow Conversational AI will change entertainment and media\nTalk to DeepSeek R1 with ElevenLabs Conversational AI\nElevenLabs raises $180M Series C to be the voice of the digital world\nFooter\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nExpanding beyond ALS to support MSA and mouth cancer patients with free AI voice technology\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nGiving cricket fans across India access to their favorite player's insights in English, Hindi, Tamil and other Indian languages.\nBring virtual experiences to life with compelling text to speech narration.\nAfter reviewing 4500 submissions (190 hours of film!) to the world's largest AI Film Festival – Project Odyssey - we can now finally reveal the grand prize winners of the ElevenLabs award.\nRian accelerates global storytelling with ElevenLabs’ AI dubbing — boosting efficiency, authenticity, and audience reach.\nAI audio is transforming the news industry, boosting engagement and accessibility through narrated articles and podcasts.\nAiMation Studios uses ElevenLabs Voice AI and sound effects models to bring characters to life and speed up its pipeline.\nPress conferences will be available in Polish, English, and French using AI-generated voices\nOver 60 companies are working to strengthen Europe’s role in global AI\nCalls now start at 10 cents per minute — an ~50% discount across Starter, Creator and Pro plans\nGemini 2.0 Flash is now available to all developers building with ElevenLabs Conversational AI\nUsing our speech technology for AI voice agents\nStudio, our longform text-to-audio editor for creators and storytellers, is now available to everyone.\nBuilding controlled AI experiences through smart architecture and guardrails\nArianna Huffington turns to ElevenLabs Voice AI technology to refresh the preface of her book Thrive for its 10th anniversary. \nConversational AI is reshaping entertainment and media, enabling more interactive and personalized experiences\nWe gave DeepSeek R1 a voice with ElevenLabs Conversational AI platform\nAnd make speech the new standard for digital interaction\nCreate with the highest quality AI Audio\nResearch\nProducts\nSolutions\nEarn As\nResources\nCompany\nReach everyone with AI audio\n© 2025 ElevenLabs"
},
{
    "url": "https://elevenlabs.io/app/sign-up",
    "text": ""
},
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
    "text": "Create speech\nPath parameters\nQuery parameters\nRequest\nResponse\nErrors\nConvert text to speech using our library of over 3,000 voices across 32 languages.\nID of the voice to be used. Use the \n endpoint list all the available voices.\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n0 - default mode (no latency optimizations)\n1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n3 - max latency optimizations\n4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\nThe output format of the generated audio.\nThe text that will get converted into speech.\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nLanguage code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.\nVoice settings overriding stored setttings for the given voice. They are applied only on the given request.\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nThe text that came before the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nThe text that comes after the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\nIf true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.\nSuccessful Response"
}
][
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/blog",
    "text": "Blog\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nOn track to help 1 million people regain their voice\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nWe’re partnering with Star Sports to localize cricket content across languages\nHow text to speech enhances virtual tours and immersive experiences\nAnnouncing the ElevenLabs Award Winners in the Project Odyssey AI Film Competition\nRian scales global storytelling with ElevenLabs’ AI Voice technology\nThe state of AI Audio in publishing and news\nAiMation Studios uses ElevenLabs to bring characters to life\nAI Dubbing for Polish Presidency of the Council of the EU\nElevenLabs joins the EU AI Champions Initiative\nWe cut our pricing for Conversational AI\nSolda.AI launches AI voice agents that can close deals\nGemini 2.0 Flash now available\nConvin adds AI voice calling to its contact center platform\nStudio is now available to everyone\nProduction-Ready Conversational AI at Enterprise Scale: With Scale AI’s Felix Su\nArianna Huffington uses ElevenLabs to refresh Thrive for its 10th anniversary\nHow Conversational AI will change entertainment and media\nTalk to DeepSeek R1 with ElevenLabs Conversational AI\nElevenLabs raises $180M Series C to be the voice of the digital world\nFooter\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nExpanding beyond ALS to support MSA and mouth cancer patients with free AI voice technology\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nGiving cricket fans across India access to their favorite player's insights in English, Hindi, Tamil and other Indian languages.\nBring virtual experiences to life with compelling text to speech narration.\nAfter reviewing 4500 submissions (190 hours of film!) to the world's largest AI Film Festival – Project Odyssey - we can now finally reveal the grand prize winners of the ElevenLabs award.\nRian accelerates global storytelling with ElevenLabs’ AI dubbing — boosting efficiency, authenticity, and audience reach.\nAI audio is transforming the news industry, boosting engagement and accessibility through narrated articles and podcasts.\nAiMation Studios uses ElevenLabs Voice AI and sound effects models to bring characters to life and speed up its pipeline.\nPress conferences will be available in Polish, English, and French using AI-generated voices\nOver 60 companies are working to strengthen Europe’s role in global AI\nCalls now start at 10 cents per minute — an ~50% discount across Starter, Creator and Pro plans\nGemini 2.0 Flash is now available to all developers building with ElevenLabs Conversational AI\nUsing our speech technology for AI voice agents\nStudio, our longform text-to-audio editor for creators and storytellers, is now available to everyone.\nBuilding controlled AI experiences through smart architecture and guardrails\nArianna Huffington turns to ElevenLabs Voice AI technology to refresh the preface of her book Thrive for its 10th anniversary. \nConversational AI is reshaping entertainment and media, enabling more interactive and personalized experiences\nWe gave DeepSeek R1 a voice with ElevenLabs Conversational AI platform\nAnd make speech the new standard for digital interaction\nCreate with the highest quality AI Audio\nResearch\nProducts\nSolutions\nEarn As\nResources\nCompany\nReach everyone with AI audio\n© 2025 ElevenLabs"
},
{
    "url": "https://elevenlabs.io/app/sign-up",
    "text": ""
},
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
    "text": "Create speech\nPath parameters\nQuery parameters\nRequest\nResponse\nErrors\nConvert text to speech using our library of over 3,000 voices across 32 languages.\nID of the voice to be used. Use the \n endpoint list all the available voices.\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n0 - default mode (no latency optimizations)\n1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n3 - max latency optimizations\n4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\nThe output format of the generated audio.\nThe text that will get converted into speech.\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nLanguage code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.\nVoice settings overriding stored setttings for the given voice. They are applied only on the given request.\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nThe text that came before the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nThe text that comes after the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\nIf true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.\nSuccessful Response"
}
][
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/blog",
    "text": "Blog\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nOn track to help 1 million people regain their voice\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nWe’re partnering with Star Sports to localize cricket content across languages\nHow text to speech enhances virtual tours and immersive experiences\nAnnouncing the ElevenLabs Award Winners in the Project Odyssey AI Film Competition\nRian scales global storytelling with ElevenLabs’ AI Voice technology\nThe state of AI Audio in publishing and news\nAiMation Studios uses ElevenLabs to bring characters to life\nAI Dubbing for Polish Presidency of the Council of the EU\nElevenLabs joins the EU AI Champions Initiative\nWe cut our pricing for Conversational AI\nSolda.AI launches AI voice agents that can close deals\nGemini 2.0 Flash now available\nConvin adds AI voice calling to its contact center platform\nStudio is now available to everyone\nProduction-Ready Conversational AI at Enterprise Scale: With Scale AI’s Felix Su\nArianna Huffington uses ElevenLabs to refresh Thrive for its 10th anniversary\nHow Conversational AI will change entertainment and media\nTalk to DeepSeek R1 with ElevenLabs Conversational AI\nElevenLabs raises $180M Series C to be the voice of the digital world\nFooter\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nExpanding beyond ALS to support MSA and mouth cancer patients with free AI voice technology\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nGiving cricket fans across India access to their favorite player's insights in English, Hindi, Tamil and other Indian languages.\nBring virtual experiences to life with compelling text to speech narration.\nAfter reviewing 4500 submissions (190 hours of film!) to the world's largest AI Film Festival – Project Odyssey - we can now finally reveal the grand prize winners of the ElevenLabs award.\nRian accelerates global storytelling with ElevenLabs’ AI dubbing — boosting efficiency, authenticity, and audience reach.\nAI audio is transforming the news industry, boosting engagement and accessibility through narrated articles and podcasts.\nAiMation Studios uses ElevenLabs Voice AI and sound effects models to bring characters to life and speed up its pipeline.\nPress conferences will be available in Polish, English, and French using AI-generated voices\nOver 60 companies are working to strengthen Europe’s role in global AI\nCalls now start at 10 cents per minute — an ~50% discount across Starter, Creator and Pro plans\nGemini 2.0 Flash is now available to all developers building with ElevenLabs Conversational AI\nUsing our speech technology for AI voice agents\nStudio, our longform text-to-audio editor for creators and storytellers, is now available to everyone.\nBuilding controlled AI experiences through smart architecture and guardrails\nArianna Huffington turns to ElevenLabs Voice AI technology to refresh the preface of her book Thrive for its 10th anniversary. \nConversational AI is reshaping entertainment and media, enabling more interactive and personalized experiences\nWe gave DeepSeek R1 a voice with ElevenLabs Conversational AI platform\nAnd make speech the new standard for digital interaction\nCreate with the highest quality AI Audio\nResearch\nProducts\nSolutions\nEarn As\nResources\nCompany\nReach everyone with AI audio\n© 2025 ElevenLabs"
},
{
    "url": "https://elevenlabs.io/app/sign-up",
    "text": ""
},
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
    "text": "Create speech\nPath parameters\nQuery parameters\nRequest\nResponse\nErrors\nConvert text to speech using our library of over 3,000 voices across 32 languages.\nID of the voice to be used. Use the \n endpoint list all the available voices.\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n0 - default mode (no latency optimizations)\n1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n3 - max latency optimizations\n4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\nThe output format of the generated audio.\nThe text that will get converted into speech.\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nLanguage code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.\nVoice settings overriding stored setttings for the given voice. They are applied only on the given request.\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nThe text that came before the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nThe text that comes after the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\nIf true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.\nSuccessful Response"
}
][
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/blog",
    "text": "Blog\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nOn track to help 1 million people regain their voice\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nWe’re partnering with Star Sports to localize cricket content across languages\nHow text to speech enhances virtual tours and immersive experiences\nAnnouncing the ElevenLabs Award Winners in the Project Odyssey AI Film Competition\nRian scales global storytelling with ElevenLabs’ AI Voice technology\nThe state of AI Audio in publishing and news\nAiMation Studios uses ElevenLabs to bring characters to life\nAI Dubbing for Polish Presidency of the Council of the EU\nElevenLabs joins the EU AI Champions Initiative\nWe cut our pricing for Conversational AI\nSolda.AI launches AI voice agents that can close deals\nGemini 2.0 Flash now available\nConvin adds AI voice calling to its contact center platform\nStudio is now available to everyone\nProduction-Ready Conversational AI at Enterprise Scale: With Scale AI’s Felix Su\nArianna Huffington uses ElevenLabs to refresh Thrive for its 10th anniversary\nHow Conversational AI will change entertainment and media\nTalk to DeepSeek R1 with ElevenLabs Conversational AI\nElevenLabs raises $180M Series C to be the voice of the digital world\nFooter\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nExpanding beyond ALS to support MSA and mouth cancer patients with free AI voice technology\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nGiving cricket fans across India access to their favorite player's insights in English, Hindi, Tamil and other Indian languages.\nBring virtual experiences to life with compelling text to speech narration.\nAfter reviewing 4500 submissions (190 hours of film!) to the world's largest AI Film Festival – Project Odyssey - we can now finally reveal the grand prize winners of the ElevenLabs award.\nRian accelerates global storytelling with ElevenLabs’ AI dubbing — boosting efficiency, authenticity, and audience reach.\nAI audio is transforming the news industry, boosting engagement and accessibility through narrated articles and podcasts.\nAiMation Studios uses ElevenLabs Voice AI and sound effects models to bring characters to life and speed up its pipeline.\nPress conferences will be available in Polish, English, and French using AI-generated voices\nOver 60 companies are working to strengthen Europe’s role in global AI\nCalls now start at 10 cents per minute — an ~50% discount across Starter, Creator and Pro plans\nGemini 2.0 Flash is now available to all developers building with ElevenLabs Conversational AI\nUsing our speech technology for AI voice agents\nStudio, our longform text-to-audio editor for creators and storytellers, is now available to everyone.\nBuilding controlled AI experiences through smart architecture and guardrails\nArianna Huffington turns to ElevenLabs Voice AI technology to refresh the preface of her book Thrive for its 10th anniversary. \nConversational AI is reshaping entertainment and media, enabling more interactive and personalized experiences\nWe gave DeepSeek R1 a voice with ElevenLabs Conversational AI platform\nAnd make speech the new standard for digital interaction\nCreate with the highest quality AI Audio\nResearch\nProducts\nSolutions\nEarn As\nResources\nCompany\nReach everyone with AI audio\n© 2025 ElevenLabs"
},
{
    "url": "https://elevenlabs.io/app/sign-up",
    "text": ""
},
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
    "text": "Create speech\nPath parameters\nQuery parameters\nRequest\nResponse\nErrors\nConvert text to speech using our library of over 3,000 voices across 32 languages.\nID of the voice to be used. Use the \n endpoint list all the available voices.\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n0 - default mode (no latency optimizations)\n1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n3 - max latency optimizations\n4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\nThe output format of the generated audio.\nThe text that will get converted into speech.\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nLanguage code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.\nVoice settings overriding stored setttings for the given voice. They are applied only on the given request.\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nThe text that came before the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nThe text that comes after the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\nIf true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.\nSuccessful Response"
}
][
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/blog",
    "text": "Blog\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nOn track to help 1 million people regain their voice\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nWe’re partnering with Star Sports to localize cricket content across languages\nHow text to speech enhances virtual tours and immersive experiences\nAnnouncing the ElevenLabs Award Winners in the Project Odyssey AI Film Competition\nRian scales global storytelling with ElevenLabs’ AI Voice technology\nThe state of AI Audio in publishing and news\nAiMation Studios uses ElevenLabs to bring characters to life\nAI Dubbing for Polish Presidency of the Council of the EU\nElevenLabs joins the EU AI Champions Initiative\nWe cut our pricing for Conversational AI\nSolda.AI launches AI voice agents that can close deals\nGemini 2.0 Flash now available\nConvin adds AI voice calling to its contact center platform\nStudio is now available to everyone\nProduction-Ready Conversational AI at Enterprise Scale: With Scale AI’s Felix Su\nArianna Huffington uses ElevenLabs to refresh Thrive for its 10th anniversary\nHow Conversational AI will change entertainment and media\nTalk to DeepSeek R1 with ElevenLabs Conversational AI\nElevenLabs raises $180M Series C to be the voice of the digital world\nFooter\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nExpanding beyond ALS to support MSA and mouth cancer patients with free AI voice technology\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nGiving cricket fans across India access to their favorite player's insights in English, Hindi, Tamil and other Indian languages.\nBring virtual experiences to life with compelling text to speech narration.\nAfter reviewing 4500 submissions (190 hours of film!) to the world's largest AI Film Festival – Project Odyssey - we can now finally reveal the grand prize winners of the ElevenLabs award.\nRian accelerates global storytelling with ElevenLabs’ AI dubbing — boosting efficiency, authenticity, and audience reach.\nAI audio is transforming the news industry, boosting engagement and accessibility through narrated articles and podcasts.\nAiMation Studios uses ElevenLabs Voice AI and sound effects models to bring characters to life and speed up its pipeline.\nPress conferences will be available in Polish, English, and French using AI-generated voices\nOver 60 companies are working to strengthen Europe’s role in global AI\nCalls now start at 10 cents per minute — an ~50% discount across Starter, Creator and Pro plans\nGemini 2.0 Flash is now available to all developers building with ElevenLabs Conversational AI\nUsing our speech technology for AI voice agents\nStudio, our longform text-to-audio editor for creators and storytellers, is now available to everyone.\nBuilding controlled AI experiences through smart architecture and guardrails\nArianna Huffington turns to ElevenLabs Voice AI technology to refresh the preface of her book Thrive for its 10th anniversary. \nConversational AI is reshaping entertainment and media, enabling more interactive and personalized experiences\nWe gave DeepSeek R1 a voice with ElevenLabs Conversational AI platform\nAnd make speech the new standard for digital interaction\nCreate with the highest quality AI Audio\nResearch\nProducts\nSolutions\nEarn As\nResources\nCompany\nReach everyone with AI audio\n© 2025 ElevenLabs"
},
{
    "url": "https://elevenlabs.io/app/sign-up",
    "text": ""
},
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
    "text": "Create speech\nPath parameters\nQuery parameters\nRequest\nResponse\nErrors\nConvert text to speech using our library of over 3,000 voices across 32 languages.\nID of the voice to be used. Use the \n endpoint list all the available voices.\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n0 - default mode (no latency optimizations)\n1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n3 - max latency optimizations\n4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\nThe output format of the generated audio.\nThe text that will get converted into speech.\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nLanguage code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.\nVoice settings overriding stored setttings for the given voice. They are applied only on the given request.\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nThe text that came before the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nThe text that comes after the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\nIf true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.\nSuccessful Response"
}
][
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/blog",
    "text": "Blog\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nOn track to help 1 million people regain their voice\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nWe’re partnering with Star Sports to localize cricket content across languages\nHow text to speech enhances virtual tours and immersive experiences\nAnnouncing the ElevenLabs Award Winners in the Project Odyssey AI Film Competition\nRian scales global storytelling with ElevenLabs’ AI Voice technology\nThe state of AI Audio in publishing and news\nAiMation Studios uses ElevenLabs to bring characters to life\nAI Dubbing for Polish Presidency of the Council of the EU\nElevenLabs joins the EU AI Champions Initiative\nWe cut our pricing for Conversational AI\nSolda.AI launches AI voice agents that can close deals\nGemini 2.0 Flash now available\nConvin adds AI voice calling to its contact center platform\nStudio is now available to everyone\nProduction-Ready Conversational AI at Enterprise Scale: With Scale AI’s Felix Su\nArianna Huffington uses ElevenLabs to refresh Thrive for its 10th anniversary\nHow Conversational AI will change entertainment and media\nTalk to DeepSeek R1 with ElevenLabs Conversational AI\nElevenLabs raises $180M Series C to be the voice of the digital world\nFooter\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nExpanding beyond ALS to support MSA and mouth cancer patients with free AI voice technology\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nGiving cricket fans across India access to their favorite player's insights in English, Hindi, Tamil and other Indian languages.\nBring virtual experiences to life with compelling text to speech narration.\nAfter reviewing 4500 submissions (190 hours of film!) to the world's largest AI Film Festival – Project Odyssey - we can now finally reveal the grand prize winners of the ElevenLabs award.\nRian accelerates global storytelling with ElevenLabs’ AI dubbing — boosting efficiency, authenticity, and audience reach.\nAI audio is transforming the news industry, boosting engagement and accessibility through narrated articles and podcasts.\nAiMation Studios uses ElevenLabs Voice AI and sound effects models to bring characters to life and speed up its pipeline.\nPress conferences will be available in Polish, English, and French using AI-generated voices\nOver 60 companies are working to strengthen Europe’s role in global AI\nCalls now start at 10 cents per minute — an ~50% discount across Starter, Creator and Pro plans\nGemini 2.0 Flash is now available to all developers building with ElevenLabs Conversational AI\nUsing our speech technology for AI voice agents\nStudio, our longform text-to-audio editor for creators and storytellers, is now available to everyone.\nBuilding controlled AI experiences through smart architecture and guardrails\nArianna Huffington turns to ElevenLabs Voice AI technology to refresh the preface of her book Thrive for its 10th anniversary. \nConversational AI is reshaping entertainment and media, enabling more interactive and personalized experiences\nWe gave DeepSeek R1 a voice with ElevenLabs Conversational AI platform\nAnd make speech the new standard for digital interaction\nCreate with the highest quality AI Audio\nResearch\nProducts\nSolutions\nEarn As\nResources\nCompany\nReach everyone with AI audio\n© 2025 ElevenLabs"
},
{
    "url": "https://elevenlabs.io/app/sign-up",
    "text": ""
},
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
    "text": "Create speech\nPath parameters\nQuery parameters\nRequest\nResponse\nErrors\nConvert text to speech using our library of over 3,000 voices across 32 languages.\nID of the voice to be used. Use the \n endpoint list all the available voices.\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n0 - default mode (no latency optimizations)\n1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n3 - max latency optimizations\n4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\nThe output format of the generated audio.\nThe text that will get converted into speech.\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nLanguage code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.\nVoice settings overriding stored setttings for the given voice. They are applied only on the given request.\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nThe text that came before the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nThe text that comes after the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\nIf true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.\nSuccessful Response"
}
][
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/blog",
    "text": "Blog\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nOn track to help 1 million people regain their voice\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nWe’re partnering with Star Sports to localize cricket content across languages\nHow text to speech enhances virtual tours and immersive experiences\nAnnouncing the ElevenLabs Award Winners in the Project Odyssey AI Film Competition\nRian scales global storytelling with ElevenLabs’ AI Voice technology\nThe state of AI Audio in publishing and news\nAiMation Studios uses ElevenLabs to bring characters to life\nAI Dubbing for Polish Presidency of the Council of the EU\nElevenLabs joins the EU AI Champions Initiative\nWe cut our pricing for Conversational AI\nSolda.AI launches AI voice agents that can close deals\nGemini 2.0 Flash now available\nConvin adds AI voice calling to its contact center platform\nStudio is now available to everyone\nProduction-Ready Conversational AI at Enterprise Scale: With Scale AI’s Felix Su\nArianna Huffington uses ElevenLabs to refresh Thrive for its 10th anniversary\nHow Conversational AI will change entertainment and media\nTalk to DeepSeek R1 with ElevenLabs Conversational AI\nElevenLabs raises $180M Series C to be the voice of the digital world\nFooter\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nExpanding beyond ALS to support MSA and mouth cancer patients with free AI voice technology\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nGiving cricket fans across India access to their favorite player's insights in English, Hindi, Tamil and other Indian languages.\nBring virtual experiences to life with compelling text to speech narration.\nAfter reviewing 4500 submissions (190 hours of film!) to the world's largest AI Film Festival – Project Odyssey - we can now finally reveal the grand prize winners of the ElevenLabs award.\nRian accelerates global storytelling with ElevenLabs’ AI dubbing — boosting efficiency, authenticity, and audience reach.\nAI audio is transforming the news industry, boosting engagement and accessibility through narrated articles and podcasts.\nAiMation Studios uses ElevenLabs Voice AI and sound effects models to bring characters to life and speed up its pipeline.\nPress conferences will be available in Polish, English, and French using AI-generated voices\nOver 60 companies are working to strengthen Europe’s role in global AI\nCalls now start at 10 cents per minute — an ~50% discount across Starter, Creator and Pro plans\nGemini 2.0 Flash is now available to all developers building with ElevenLabs Conversational AI\nUsing our speech technology for AI voice agents\nStudio, our longform text-to-audio editor for creators and storytellers, is now available to everyone.\nBuilding controlled AI experiences through smart architecture and guardrails\nArianna Huffington turns to ElevenLabs Voice AI technology to refresh the preface of her book Thrive for its 10th anniversary. \nConversational AI is reshaping entertainment and media, enabling more interactive and personalized experiences\nWe gave DeepSeek R1 a voice with ElevenLabs Conversational AI platform\nAnd make speech the new standard for digital interaction\nCreate with the highest quality AI Audio\nResearch\nProducts\nSolutions\nEarn As\nResources\nCompany\nReach everyone with AI audio\n© 2025 ElevenLabs"
},
{
    "url": "https://elevenlabs.io/app/sign-up",
    "text": ""
},
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
    "text": "Create speech\nPath parameters\nQuery parameters\nRequest\nResponse\nErrors\nConvert text to speech using our library of over 3,000 voices across 32 languages.\nID of the voice to be used. Use the \n endpoint list all the available voices.\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n0 - default mode (no latency optimizations)\n1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n3 - max latency optimizations\n4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\nThe output format of the generated audio.\nThe text that will get converted into speech.\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nLanguage code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.\nVoice settings overriding stored setttings for the given voice. They are applied only on the given request.\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nThe text that came before the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nThe text that comes after the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\nIf true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.\nSuccessful Response"
}
][
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/blog",
    "text": "Blog\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nOn track to help 1 million people regain their voice\nSpotify is now accepting Audiobooks narrated by ElevenLabs\nWe’re partnering with Star Sports to localize cricket content across languages\nHow text to speech enhances virtual tours and immersive experiences\nAnnouncing the ElevenLabs Award Winners in the Project Odyssey AI Film Competition\nRian scales global storytelling with ElevenLabs’ AI Voice technology\nThe state of AI Audio in publishing and news\nAiMation Studios uses ElevenLabs to bring characters to life\nAI Dubbing for Polish Presidency of the Council of the EU\nElevenLabs joins the EU AI Champions Initiative\nWe cut our pricing for Conversational AI\nSolda.AI launches AI voice agents that can close deals\nGemini 2.0 Flash now available\nConvin adds AI voice calling to its contact center platform\nStudio is now available to everyone\nProduction-Ready Conversational AI at Enterprise Scale: With Scale AI’s Felix Su\nArianna Huffington uses ElevenLabs to refresh Thrive for its 10th anniversary\nHow Conversational AI will change entertainment and media\nTalk to DeepSeek R1 with ElevenLabs Conversational AI\nElevenLabs raises $180M Series C to be the voice of the digital world\nFooter\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nExpanding beyond ALS to support MSA and mouth cancer patients with free AI voice technology\nMore people are listening to audiobooks than ever before. But for many independent authors, getting an audio version of their work published on major platforms has been expensive and time-consuming — until now.\nGiving cricket fans across India access to their favorite player's insights in English, Hindi, Tamil and other Indian languages.\nBring virtual experiences to life with compelling text to speech narration.\nAfter reviewing 4500 submissions (190 hours of film!) to the world's largest AI Film Festival – Project Odyssey - we can now finally reveal the grand prize winners of the ElevenLabs award.\nRian accelerates global storytelling with ElevenLabs’ AI dubbing — boosting efficiency, authenticity, and audience reach.\nAI audio is transforming the news industry, boosting engagement and accessibility through narrated articles and podcasts.\nAiMation Studios uses ElevenLabs Voice AI and sound effects models to bring characters to life and speed up its pipeline.\nPress conferences will be available in Polish, English, and French using AI-generated voices\nOver 60 companies are working to strengthen Europe’s role in global AI\nCalls now start at 10 cents per minute — an ~50% discount across Starter, Creator and Pro plans\nGemini 2.0 Flash is now available to all developers building with ElevenLabs Conversational AI\nUsing our speech technology for AI voice agents\nStudio, our longform text-to-audio editor for creators and storytellers, is now available to everyone.\nBuilding controlled AI experiences through smart architecture and guardrails\nArianna Huffington turns to ElevenLabs Voice AI technology to refresh the preface of her book Thrive for its 10th anniversary. \nConversational AI is reshaping entertainment and media, enabling more interactive and personalized experiences\nWe gave DeepSeek R1 a voice with ElevenLabs Conversational AI platform\nAnd make speech the new standard for digital interaction\nCreate with the highest quality AI Audio\nResearch\nProducts\nSolutions\nEarn As\nResources\nCompany\nReach everyone with AI audio\n© 2025 ElevenLabs"
},
{
    "url": "https://elevenlabs.io/app/sign-up",
    "text": ""
},
{
    "url": "https://elevenlabs.io/docs/overview",
    "text": "Most popular\nMeet the models\nCapabilities\nProduct guides\nElevenLabs\nElevenLabs is an AI audio research and deployment company.\nLearn how to integrate ElevenLabs\nDeploy voice agents in minutes\nLearn how to use ElevenLabs\nDive into our API reference\nOur most lifelike, emotionally rich speech synthesis model\nOur fast, affordable speech synthesis model\nConvert text into lifelike speech\nModify and transform voices\nIsolate voices from background noise\nDub audio and videos seamlessly\nCreate cinematic sound effects\nClone and design custom voices\nDeploy intelligent voice agents\nExplore our product guides for step-by-step guidance"
},
{
    "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
    "text": "Create speech\nPath parameters\nQuery parameters\nRequest\nResponse\nErrors\nConvert text to speech using our library of over 3,000 voices across 32 languages.\nID of the voice to be used. Use the \n endpoint list all the available voices.\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n0 - default mode (no latency optimizations)\n1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n3 - max latency optimizations\n4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\nThe output format of the generated audio.\nThe text that will get converted into speech.\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nLanguage code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.\nVoice settings overriding stored setttings for the given voice. They are applied only on the given request.\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nThe text that came before the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nThe text that comes after the text of the current request. Can be used to improve the speech’s continuity when concatenating together multiple generations or to influence the speech’s continuity in the current generation.\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\nIf true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.\nSuccessful Response"
}
]